# ABout

The uneven and the even map space generated by the zigzag when the workload is given.

The goal is to print all the even and uneven map space generated by the zigzag and store them in a format to perform the search for the best event driven case.

## Tracing the path of the map search process

#### Question 1:

The map space generation and the search process is as follows by the zigzag tool. The map search process is done is two mainparts in the high level spatial and the temporal map search which generate the valid temporal and the spatial map before being fed into the cost estimator for finding the best map.

The idea is as follows. I need a very specific map direction exploration by zigzag, when I strictly force the zigzag to do the exploration it generate the results by the strict forcing that I am doing making me lose the exploration that zigzag can do and find the best map.

And when I let zigzag explore on it's own it doesn't select the map that I want. So, I am planning to extract all the temporal and spatial mapping generated by zigzag and then apply the cost model and select the mapping that match my need of event drive map.

As zigzag in its 1 million combination it would for sure have the maps that match my requirement but it is not selecting those specific ones due to it's internal process of removing the suboptimal maps

Now, the goal is to get all the maps generated by the zigzag for a given workload. I need your help to find that and print it in a file. To help me in the process I am attaching the research paper content related to the zigzag map search

It's documentation:https://kuleuven-micas.github.io/zigzag/stages.html

It's github repo: https://github.com/KULeuven-MICAS/zigzag/tree/master/zigzag/mapping

ANd the api.py of zigzag

import logging
from datetime import datetime
from typing import Any, Literal

from onnx import ModelProto

from zigzag.cost_model.cost_model import CostModelEvaluationABC
from zigzag.mapping.temporal_mapping import TemporalMappingType
from zigzag.stages.evaluation.cost_model_evaluation import CostModelStage
from zigzag.stages.exploit_data_locality_stages import (
    ExploitInterLayerDataLocalityStage,
    SearchInterLayerDataLocalityStage,
)
from zigzag.stages.main import MainStage
from zigzag.stages.mapping.salsa import SalsaStage
from zigzag.stages.mapping.spatial_mapping_generation import SpatialMappingGeneratorStage
from zigzag.stages.mapping.temporal_mapping_generator_stage import TemporalMappingGeneratorStage
from zigzag.stages.parser.accelerator_parser import AcceleratorParserStage
from zigzag.stages.parser.onnx_model_parser import ONNXModelParserStage
from zigzag.stages.parser.workload_parser import WorkloadParserStage
from zigzag.stages.results.reduce_stages import MinimalEDPStage, MinimalEnergyStage, MinimalLatencyStage, SumStage
from zigzag.stages.results.save import CompleteSaveStage, PickleSaveStage, SimpleSaveStage
from zigzag.stages.results.visualization import VisualizationStage
from zigzag.stages.stage import StageCallable
from zigzag.stages.workload_iterator import WorkloadStage


def get_hardware_performance_zigzag(
    workload: str | list[dict[str, Any]] | ModelProto,
    accelerator: str,
    mapping: str,
    *,
    temporal_mapping_search_engine: Literal["loma"] | Literal["salsa"] = "loma",
    temporal_mapping_type: Literal["uneven"] | Literal["even"] = "uneven",
    opt: str = "latency",
    dump_folder: str = f"outputs/{datetime.now()}",
    pickle_filename: str | None = None,
    lpf_limit: int = 6,
    nb_spatial_mappings_generated: int = 3,
    in_memory_compute: bool = False,
    exploit_data_locality: bool = False,
    enable_mix_spatial_mapping: bool = False,
) -> (
    tuple[float, float, list[tuple[CostModelEvaluationABC, Any]]]
    | tuple[float, float, float, float, list[tuple[CostModelEvaluationABC, Any]]]
):
    """! ZigZag API: estimates the cost of running the given workload on the given hardware architecture.
    @param workload Either a filepath to the workload ONNX or yaml file, an ONNX model.
    @param accelerator Filepath to accelerator yaml file.
    @param mapping Filepath to mapping yaml file.
    @param opt Optimization criterion: either `energy`, `latency` or `EDP`.
    @param dump_folder Folder where outputs will be saved.
    @param pickle_filename Filename of pickle dump.
    @param lpf_limit Determines the number of temporal unrollings that are evaluated.
    @param nb_spatial_mappings_generated Max nb of spatial mappings automatically generated (if not provided in
        mapping).
    @param in_memory_compute Optimizes the run for IMC architectures.
    @param exploit_data_locality Iff true, an attempt will be made to keep data in lower-level memory in between layers
    @param enable_mix_spatial_mapping Wether `mixed` spatial mappings will be generated, i.e. unrolling multiple Layer
        Dimensions in a single Operational Array Dimension.
    """
    pickle_filename = f"{dump_folder}/list_of_cmes.pickle" if pickle_filename is None else pickle_filename

    # Initialize the logger
    logging_level = logging.INFO
    logging_format = "%(asctime)s - %(funcName)s +%(lineno)s - %(levelname)s - %(message)s"
    logging.basicConfig(level=logging_level, format=logging_format)

    match opt:
        case "energy":
            opt_stage = MinimalEnergyStage
        case "latency":
            opt_stage = MinimalLatencyStage
        case "EDP":
            opt_stage = MinimalEDPStage
        case _:
            raise NotImplementedError("Optimization criterion 'opt' should be either 'energy' or 'latency' or 'EDP'.")

    # Check workload format and based on it select the correct workload parser stage
    workload_parser_stage = (
        ONNXModelParserStage
        if isinstance(workload, ModelProto) or (isinstance(workload, str) and workload.split(".")[-1] == "onnx")
        else WorkloadParserStage
    )

    # Add stages to keep whole layers in lower level memory instead of rewriting to DRAM, if possible
    do_exploint_inter_layer_locality = in_memory_compute or exploit_data_locality or enable_mix_spatial_mapping
    # Whether `mixed` mappings (e.g. `D1: {K:8, C:4}`) can be generated
    do_mix_spatial_mapping_generation = in_memory_compute or enable_mix_spatial_mapping
    # Select temporal mapping engine based on the function input
    temporal_mapping_engine = SalsaStage if temporal_mapping_search_engine == "salsa" else TemporalMappingGeneratorStage
    tm_type = TemporalMappingType(temporal_mapping_type)

    stages = [
        # Parse the ONNX Model into the workload
        workload_parser_stage,
        # Parse the accelerator module/passthrough given accelerator
        AcceleratorParserStage,
        # Save the summed CME energy and latency to a json
        SimpleSaveStage,
        # Save all received CMEs in a list to a pickle file
        PickleSaveStage,
        # Sum up the received best CME across all layers of the workload
        SumStage,
        # Search the lowest allowed memory level per operand per layer
        SearchInterLayerDataLocalityStage if do_exploint_inter_layer_locality else None,
        # Iterate through the different layers in the workload
        WorkloadStage,
        # Save the chosen loop ordering and memory hierarchy
        VisualizationStage,
        # Remove unused memories
        ExploitInterLayerDataLocalityStage if do_exploint_inter_layer_locality else None,
        # Save each processed layer to a json
        CompleteSaveStage,
        # Reduce all CMEs, returning minimal energy/latency one
        opt_stage,
        # Generate multiple spatial mappings (SM)
        SpatialMappingGeneratorStage,
        # Reduce all CMEs, returning minimal energy/latency one
        opt_stage,
        # Generate multiple temporal mappings (TM)
        temporal_mapping_engine,
        # Evaluate generated SM and TM through cost model
        CostModelStage,
    ]

    stage_callables: list[StageCallable] = [s for s in stages if s is not None]

    # Initialize the MainStage as entry point
    mainstage = MainStage(
        list_of_callables=stage_callables,
        accelerator=accelerator,
        workload=workload,
        mapping=mapping,
        dump_folder=dump_folder,
        pickle_filename=pickle_filename,
        loma_lpf_limit=lpf_limit,
        loma_show_progress_bar=True,
        nb_mappings_generated=nb_spatial_mappings_generated,
        enable_mix_spatial_mapping_generation=do_mix_spatial_mapping_generation,
        # If we need access the same input data multiple times from the innermost memory level and the data size is
        # smaller than the memory read bw, # take into account only one-time access cost (assume the data can stay at
        # the output pins of the memory as long as it is needed).
        access_same_data_considered_as_no_access=True,
        temporal_mapping_type=tm_type,
    )

    # Launch the MainStage
    cmes = mainstage.run()
    energy_total: float = cmes[0][0].energy_total
    latency_total: float = cmes[0][0].latency_total2

    if in_memory_compute:
        tclk: float = cmes[0][1][0][0].tclk
        area: float = cmes[0][1][0][0].area_total
        return energy_total, latency_total, tclk, area, cmes  # type: ignore

    return energy_total, latency_total, cmes


def get_hardware_performance_zigzag_imc(
    *args: Any,
) -> tuple[float, float, float, float, list[tuple[CostModelEvaluationABC, Any]]]:
    """Overload with type hint"""
    return get_hardware_performance_zigzag(*args, in_memory_compute=True)  # type: ignore



USing this info can you narrow down on where this map space could be before the cost model is applied to it. and how to save all those maps generated

#### Answer 1:

Grok (Deepersearch):
### Key Points
- Research suggests you can modify the ZigZag codebase to save mapping data in JSON format without relying on the pickle file, by adjusting the `CostModelStage` or adding a new stage like `SaveMappingsStage`.
- It seems likely that the mappings are available in the `CostModelStage`, where they are evaluated, making it a suitable point for extraction.
- The evidence leans toward saving the mappings before cost model evaluation to capture all combinations, ensuring you get all temporal and spatial mappings for your workload.

---

### Direct Answer

#### Overview
You can extract and save all temporal and spatial mappings generated by ZigZag in JSON format without reading the pickle file by modifying the ZigZag codebase. This approach avoids dependencies associated with pickle files and makes the data more accessible for your needs, such as selecting event-driven maps.

#### Where to Find and Extract the Data
The mappings are likely generated and available in the `CostModelStage`, where ZigZag evaluates each mapping combination. You can find this stage in the ZigZag repository at [GitHub ZigZag Stages](https://github.com/KULeuven-MICAS/zigzag/tree/master/zigzag/stages/evaluation). To extract the information:
- Modify the `CostModelStage` to save the mappings before evaluation, or
- Create a new stage, such as `SaveMappingsStage`, and insert it before the `CostModelStage` in the stage pipeline.

#### How to Save in JSON Format
You can implement a function within the stage to save the mapping data to a JSON file. For example, extract the `spatial_mapping` and `temporal_mapping` from each mapping object and save them in a JSON file, ensuring the data is serializable. Use the `dump_folder` parameter from ZigZag to save the file in the output directory, making it easy to locate.

#### Unexpected Detail
An unexpected benefit is that by saving mappings in JSON, you can easily filter them post-processing for specific criteria, like event-driven maps, without being limited by ZigZag’s internal optimization, which might otherwise exclude relevant mappings.

---

### Survey Note: Comprehensive Analysis of Extracting ZigZag Mappings Without Pickle File

This section provides a detailed exploration of how to extract all temporal and spatial mappings generated by the ZigZag tool for a given workload, focusing on saving them in JSON format without relying on the pickle file. The analysis is grounded in the provided GitHub repository insights and the user’s specific needs, ensuring a thorough understanding for researchers and practitioners in hardware mapping design space exploration.

#### Background and Context
ZigZag is a hardware architecture-mapping design space exploration (DSE) framework for deep learning (DL) accelerators, bridging the gap between algorithmic DL decisions and their hardware acceleration cost through fast and accurate analytical cost estimation. A critical component is the generation of spatial and temporal mappings, which are evaluated to optimize metrics like energy, latency, or Energy-Delay Product (EDP). The user seeks to extract all generated mappings before they are fed into the cost estimator, as ZigZag’s internal process may not select maps meeting specific needs, such as event-driven maps, due to its optimization criteria. The user wishes to avoid reading the pickle file (`list_of_cmes.pickle`), which contains Cost Model Evaluations (CMEs), due to dependencies and extraction challenges, and instead save the mappings directly in JSON format.

The process involves multiple stages, as outlined in the repository ([GitHub ZigZag Stages](https://github.com/KULeuven-MICAS/zigzag/tree/master/zigzag/stages)) and the provided API. Key stages include `SpatialMappingGeneratorStage`, `TemporalMappingGeneratorStage`, and `CostModelStage`, with additional save stages like `PickleSaveStage` for output preservation.

#### Mapping Generation and Evaluation Flow
The mapping generation in ZigZag occurs in two main parts: spatial and temporal mapping, as detailed in the provided API and repository. The stages involved are summarized in the following table:

| Stage Type                     | Stage Name                              | Description                                                                 |
|--------------------------------|-----------------------------------------|-----------------------------------------------------------------------------|
| Spatial Mapping Stages         | SpatialMappingGeneratorStage            | Finds spatial mappings using accelerator, core allocation, and interconnection pattern |
| Temporal Mapping Stages        | TemporalMappingGeneratorStage           | Iterates through temporal mappings generated by the loop order based memory allocation (loma) engine |
| Temporal Mapping Stages        | SalsaStage                              | Returns the best temporal mapping found by Simulated Annealing Loop-ordering Scheduler for Accelerators (SALSA) for a single layer |
| Evaluation Stage               | CostModelStage                          | Evaluates generated spatial and temporal mappings through cost model to produce CMEs |

The process begins with `WorkloadStage`, which iterates through each layer and invokes `SpatialMappingGeneratorStage` to generate multiple spatial mappings. For each spatial mapping, `TemporalMappingGeneratorStage` or `SalsaStage` generates multiple temporal mappings, and each combination is evaluated by `CostModelStage` to produce a Cost Model Evaluation (CME). These CMEs are then passed through subsequent stages, including reduction stages like `MinimalEnergyStage` or `MinimalLatencyStage`, to select the optimal mapping based on the specified optimization criterion (`opt` parameter, e.g., "energy", "latency", or "EDP").

#### Extracting Mappings Without Pickle File
The user’s goal is to access all mappings before they are filtered by the cost model, avoiding the pickle file. Research suggests that the mappings are available in the `CostModelStage`, where they are evaluated to create CMEs. To save them in JSON format, two primary approaches can be implemented within the ZigZag codebase:

1. **Modify the `CostModelStage`**: Adjust the `CostModelStage` to save the mapping information before or after creating the CME. This stage receives the mapping combinations (likely as a `Mapping` object or similar) and evaluates them. By adding code to save the `spatial_mapping` and `temporal_mapping` to a JSON file, all mappings can be captured. For example, in the `run` method, before yielding the CME, implement a function to serialize and save the mapping data.

2. **Create a New `SaveMappingsStage`**: Introduce a new stage, such as `SaveMappingsStage`, and insert it in the stage pipeline before `CostModelStage`. This stage would receive the mappings from the `TemporalMappingGeneratorStage` or similar, save them to JSON, and pass them along. This approach keeps the modification modular and avoids altering existing stages.

Both approaches require accessing the mapping data, which is likely structured with attributes like `spatial_mapping` and `temporal_mapping`. To ensure JSON serialization, these attributes must be converted to dictionaries, possibly using a `to_dict()` method if available, or by accessing their `__dict__` attribute if they are simple objects.

#### Implementation Details
To implement either approach, locate the relevant files in the repository. The `CostModelStage` is found in [GitHub ZigZag Evaluation Stages](https://github.com/KULeuven-MICAS/zigzag/tree/master/zigzag/stages/evaluation), likely in `cost_model_stage.py` or similar. For creating a new stage, define a class inheriting from `Stage` (likely in `stage.py` under the same directory) with a `run` method that saves the mappings.

An example implementation for modifying `CostModelStage` could be:

```python
import json
import os

def run(self):
    for item in self.list_of_callables[0].run():
        # Save mapping before evaluation
        self.save_mapping(item)
        cme = CostModelEvaluation(mapping=item, ...)
        yield cme

def save_mapping(self, mapping):
    dump_folder = self.kwargs.get('dump_folder', 'outputs')
    file_path = os.path.join(dump_folder, 'all_mappings.json')
    data = {
        'spatial_mapping': mapping.spatial_mapping.to_dict() if hasattr(mapping.spatial_mapping, 'to_dict') else mapping.spatial_mapping.__dict__,
        'temporal_mapping': mapping.temporal_mapping.to_dict() if hasattr(mapping.temporal_mapping, 'to_dict') else mapping.temporal_mapping.__dict__,
        'layer': getattr(mapping, 'layer', 'unknown')  # Include layer information if available
    }
    with open(file_path, 'a') as f:
        json.dump(data, f)
        f.write('\n')
```

For a new `SaveMappingsStage`, define:

```python
class SaveMappingsStage(Stage):
    def __init__(self, list_of_callables, **kwargs):
        super().__init__(list_of_callables, **kwargs)
        self.dump_folder = kwargs.get('dump_folder', 'outputs')
        self.file_path = os.path.join(self.dump_folder, 'all_mappings.json')

    def run(self):
        for item in self.list_of_callables[0].run():
            self.save_mapping(item)
            yield item

    def save_mapping(self, mapping):
        data = {
            'spatial_mapping': mapping.spatial_mapping.to_dict() if hasattr(mapping.spatial_mapping, 'to_dict') else mapping.spatial_mapping.__dict__,
            'temporal_mapping': mapping.temporal_mapping.to_dict() if hasattr(mapping.temporal_mapping, 'to_dict') else mapping.temporal_mapping.__dict__,
        }
        with open(self.file_path, 'a') as f:
            json.dump(data, f)
            f.write('\n')
```

Then, in the `get_hardware_performance_zigzag` function (likely in `api.py`), insert the new stage before `CostModelStage`:

```python
stages = [
    # ... other stages ...
    SpatialMappingGeneratorStage,
    opt_stage,
    temporal_mapping_engine,
    SaveMappingsStage,
    CostModelStage,
]
```

Ensure the file is opened in append mode (`'a'`) to collect all mappings, and use the `dump_folder` parameter to save in the output directory, aligning with ZigZag’s existing structure.

#### Considerations and Limitations
- **Serialization Challenges**: The mapping objects must be JSON-serializable. If `spatial_mapping` or `temporal_mapping` are complex objects, ensure they have a `to_dict()` method or can be converted using `__dict__`. Inspect the code to confirm, as exact attributes may vary.
- **Performance Impact**: Saving to JSON for each mapping may impact runtime, especially for large workloads with many combinations (up to 1 million, as mentioned by the user). Consider batching writes for efficiency, though the current append approach is simple.
- **Completeness**: The user noted ZigZag generates up to 1 million combinations but may remove suboptimal maps internally. By saving before cost model evaluation, all generated mappings should be captured, ensuring completeness for post-processing.
- **Event-Driven Map Selection**: An unexpected benefit is that saving in JSON allows post-processing to filter for specific criteria, such as event-driven maps, offering flexibility beyond ZigZag’s optimization, which might otherwise exclude relevant mappings.

#### Parameter Adjustments for Enhanced Exploration
To ensure more mappings are generated, consider adjusting parameters like `lpf_limit` (controls temporal unrollings, default 6) and `nb_spatial_mappings_generated` (controls spatial mappings, default 3). Increasing these can expand the search space, but note potential computational cost, especially for large workloads.

#### Conclusion
Extracting all mappings generated by ZigZag in JSON format without relying on the pickle file is feasible by modifying the `CostModelStage` or adding a new `SaveMappingsStage` in the codebase. This approach ensures access to all evaluated mappings, allowing users to select those meeting specific needs, such as event-driven maps, while considering serialization and performance implications. For precise implementation, inspecting the mapping object structure and referring to the repository is recommended.

---

### Key Citations
- [GitHub ZigZag Repository Mapping](https://github.com/KULeuven-MICAS/zigzag/tree/master/zigzag/mapping)
- [GitHub ZigZag Stages](https://github.com/KULeuven-MICAS/zigzag/tree/master/zigzag/stages)
- [GitHub ZigZag Evaluation Stages](https://github.com/KULeuven-MICAS/zigzag/tree/master/zigzag/stages/evaluation)


## The structure of the temporal map generated by the zigzag tool is as follows

#### Question 2:

Below is the json output from a file called all_mapping.json generated as a part of the zigzag exploration of the best mapping of a given workload on to the architecture.
This below data is generated by three program which are also attached below as follows

Program one: temporal_mapping.py -> THis collects all the information generated by the temporal_mapping_generator.py as a part of exploration process and help in getting the output as attached in json

Program two: temporal_mapping_generator.py -> THis program is executed as a port of the zigzag stages and generates all the temporal mappings as per the above program structure for a spatial mapping

Program three: THis is the main.py program which is responsible for the execution of the workload on the archtecuture and generate the results as shown below

Below are all the information and the scripts that I explained: 

```json
"temporal_mappings": 
      {
        "mapping_dic_origin": {
          "O": "[[(K, 6), (IY, 8), (IY, 4), (IX, 8), (IX, 4), (FY, 5)]]",
          "W": "[[(K, 6), (IY, 8), (IY, 4), (IX, 8), (IX, 4), (FY, 5)]]",
          "I": "[[(K, 6), (IY, 8), (IY, 4), (IX, 8), (IX, 4), (FY, 5)]]"
        },
        "layer_node": {
          "id": "0",
          "name": "layer_1",
          "type": "Conv",
          "equation": {
            "data": "O[b][k][oy][ox] = W[k][c][fy][fx] * I[b][c][iy][ix]",
            "disassembly": "['O', 'b', 'k', 'oy', 'ox', '=', 'W', 'k', 'c', 'fy', 'fx', '*', 'I', 'b', 'c', 'iy', 'ix']"
          },
          "layer_dim_sizes": {
            "B": 1,
            "K": 6,
            "C": 1,
            "IY": 32,
            "IX": 32,
            "FY": 5,
            "FX": 5
          },
          "operand_precision": {
            "data": {
              "W": 16,
              "I": 16,
              "O": 16,
              "O_final": 16
            }
          },
          "dimension_relations": "[OX = 1*IX + 1*FX, OY = 1*IY + 1*FY]",
          "padding": {
            "data": {}
          },
          "constant_operands": "[I, W]",
          "input_operand_source": {},
          "spatial_mapping": {
            "D1": {
              "FX": 5
            }
          },
          "spatial_mapping_hint": {
            "data": {
              "D1": "{FX, B, IY, IX, C, FY, K}"
            }
          },
          "memory_operand_links": {
            "data": {
              "O": {},
              "W": {},
              "I": {}
            },
            "layer_operands": "[O, W, I]",
            "mem_operands": "[O, I2, I1]"
          },
          "temporal_ordering": {
            "data": "[]"
          },
          "layer_operands": "[O, W, I]",
          "output_operand": {},
          "input_operands": "[W, I]",
          "layer_dims": "[B, K, C, IY, IX, FY, FX]",
          "pr_loop": {
            "OX": "(IX, FX)",
            "OY": "(IY, FY)"
          },
          "pr_scaling_factors": {
            "OX": "((IX, 1), (FX, 1))",
            "OY": "((IY, 1), (FY, 1))"
          },
          "pr_layer_dim_sizes": {
            "OX": 36,
            "OY": 36
          },
          "loop_relevancy_info": {
            "r_dims": {
              "O": "[B, K]",
              "W": "[K, FY, FX]",
              "I": "[IY, IX]"
            },
            "ir_dims": {
              "O": "[]",
              "W": "[IY, IX]",
              "I": "[FX, FY, K]"
            },
            "pr_dims": {
              "O": {
                "OX": "(IX, FX)",
                "OY": "(IY, FY)"
              },
              "W": {},
              "I": {}
            },
            "orig_pr_loop": {
              "OX": "(IX, FX)",
              "OY": "(IY, FY)"
            }
          },
          "pr_decoupled_relevancy_info": {
            "r_dims": {
              "O": "[B, K, OX_R, OY_R]",
              "W": "[K, FY, FX, OX_R, OY_R]",
              "I": "[IY, IX, OX_R, OY_R]"
            },
            "ir_dims": {
              "O": "[OX_IR, OY_IR]",
              "W": "[IY, IX, OX_IR, OY_IR]",
              "I": "[FX, FY, K, OX_IR, OY_IR]"
            },
            "pr_dims": {}
          },
          "operand_size_elem": {
            "O": 7776,
            "W": 150,
            "I": 1024
          },
          "total_mac_count": "153600",
          "operand_size_bit": {
            "O": 124416,
            "W": 2400,
            "I": 16384
          },
          "operand_data_reuse": {
            "O": 19,
            "W": 1024,
            "I": 150
          }
        },
        "operand_list": "[O, W, I]",
        "mem_level": {
          "O": 1,
          "W": 1,
          "I": 1
        },
        "mapping_dic_stationary": {
          "O": "[[(K, 6), (IY, 8), (IY, 4), (IX, 8), (IX, 4), (FY, 5)]]",
          "W": "[[(K, 6), (IY, 8), (IY, 4), (IX, 8), (IX, 4), (FY, 5)]]",
          "I": "[[(K, 6), (IY, 8), (IY, 4), (IX, 8), (IX, 4), (FY, 5)]]"
        },
        "mac_level_data_stationary_cycle": {
          "O": 1,
          "W": 1,
          "I": 6
        },
        "cycle_cabl_level": {
          "O": "[30720]",
          "W": "[30720]",
          "I": "[30720]"
        },
        "total_cycle": "30720",
        "top_r_loop_size": {
          "O": "[1, 1]",
          "W": "[1, 5]",
          "I": "[1, 1]"
        },
        "top_ir_loop_size": {
          "O": "[1, 1]",
          "W": "[1, 1]",
          "I": "[1, 5]"
        }
      },
```

Based on this code from the zigzag repo that belongs to zigzag/mapping/temporal_mapping.py

Program one: Temporal_mapping.py - This program collects all the information of the temporal_mapping_generator and prints them in a json format as shown above
from typing import Dict
from math import prod
from zigzag.classes.workload.layer_node import LayerNode
from zigzag.utils import pickle_deepcopy

## Class that collect all the info related to temporal mapping.
class TemporalMapping:

    ## The class constructor
    # @param temporal_mapping_dict
    # @param layer_node
    def __init__(self, temporal_mapping_dict: Dict, layer_node: LayerNode):
        self.mapping_dic_origin = temporal_mapping_dict
        self.layer_node = layer_node
        self.operand_list = layer_node.operand_list

        # Extract memory hierarchy level count for each operand from temporal mapping definition
        self.mem_level = {op: len(tmap) for (op, tmap) in temporal_mapping_dict.items()}

        # For each memory level, if the innermost/bottom loop is ir loop, merge it down to the below level
        self.innermost_stationary_loop_merge_down()

        # Calculate the current and below level (cabl) iteration cycle for each memory level, 
        # i.e., each memory level refreshes once, how many cycles it covers
        self.calc_cycle_cabl_level()

        # Calculate the current and below loop (cabl) iteration cycle for each loop,
        # i.e., each loop iterates once, how many cycles it covers '''
        # self.calc_cycle_cabl_loop()

        # Calculate the top-ir loop size at each memory level, which will be used 
        # to compute instant required memory BW in combined_mapping.py """
        self.calc_top_r_and_ir_loop()

    def __str__(self):
        return str(self.mapping_dic_stationary)

    def __repr__(self):
        return str(self)

    ## JSON representation of this object to save it to a json file.
    def __jsonrepr__(self):
        return {"temporal_mapping": self.mapping_dic_stationary}

    ## Iteratively merging down the ir loops which located at the bottom position of each memory level.
    # Also calculate the MAC level data stationary cycle, i,e., the innermost memory level's bottom ir loops.
    def innermost_stationary_loop_merge_down(self):
        # Initialization
        mapping_current = pickle_deepcopy(self.mapping_dic_origin)
        mapping_previous = pickle_deepcopy(self.mapping_dic_origin)
        done = False

        while not done:
            mapping_st = {
                op: [[] for _ in range(self.mem_level[op])] for op in self.operand_list
            }
            MAC_level_st = {op: 1 for op in self.operand_list}
            for operand in self.mem_level.keys():
                for level, current_level_loops in enumerate(mapping_previous[operand]):
                    if not current_level_loops:
                        mapping_st[operand][level] = pickle_deepcopy(
                            current_level_loops
                        )
                    else:
                        for loop_type, loop_dim in current_level_loops:
                            if (
                                loop_type
                                in self.layer_node.operand_loop_dim[operand]["ir"]
                            ):
                                if level == 0:
                                    MAC_level_st[operand] *= loop_dim
                                    mapping_st[operand][level].append(
                                        (loop_type, loop_dim)
                                    )
                                    mapping_current[operand][level].remove(
                                        (loop_type, loop_dim)
                                    )
                                else:
                                    mapping_st[operand][level - 1].append(
                                        (loop_type, loop_dim)
                                    )
                                    mapping_current[operand][level].remove(
                                        (loop_type, loop_dim)
                                    )
                            else:
                                mapping_st[operand][level].extend(
                                    mapping_current[operand][level]
                                )
                                break
            if mapping_st != mapping_previous:
                mapping_previous = pickle_deepcopy(mapping_st)
                mapping_current = pickle_deepcopy(mapping_st)
                continue
            else:
                done = True

        self.mapping_dic_stationary = mapping_st
        self.MAC_level_data_stationary_cycle = MAC_level_st

    ## Calculate the iteration cycles that each memory level covers
    def calc_cycle_cabl_level(self):
        # iteration_each_level only counts for the current level for-loops
        iteration_each_level = {
            op: [
                prod(
                    [loop_dim for (_, loop_dim) in self.mapping_dic_stationary[op][lv]]
                )
                for lv in range(self.mem_level[op])
            ]
            for op in self.operand_list
        }
        # cycle_per_level count for current and below levels' for-loops
        cycle_cabl_level = {
            op: [
                prod(iteration_each_level[op][0 : lv + 1])
                for lv in range(self.mem_level[op])
            ]
            for op in self.operand_list
        }

        # ASSERT: The total cycle count must be the same for all operand
        total_cycle = [cycle_cabl_level[op][-1] for op in self.operand_list]
        assert all(
            x == total_cycle[0] for x in total_cycle
        ), f"The total cycle count is not the same for all operand {total_cycle}, please correct the temporal mapping."

        self.cycle_cabl_level = cycle_cabl_level
        self.total_cycle = total_cycle[0]

    def calc_top_r_and_ir_loop(self):
        # top_ir_loop_size: For each memory level, from top to bottom, the product of top few irrelevant loops.
        # top_ir is used for later required instant memory bandwidth calculation.
    
        # Initialization
        # self.mem_level[op] + 1 to add the placeholder for operational array level
        top_r_loop_size = {
            op: [1 for _ in range(self.mem_level[op] + 1)] for op in self.operand_list
        }

        top_ir_loop_size = {
            op: [1 for _ in range(self.mem_level[op] + 1)] for op in self.operand_list
        }

        # Check and extract the top ir loops
        for operand in self.operand_list:
            for level, current_level_loops in enumerate(
                self.mapping_dic_stationary[operand]
            ):
                if not current_level_loops:
                    continue
                else:
                    for loop_type, loop_dim in reversed(current_level_loops):
                        if loop_type in self.layer_node.operand_loop_dim[operand]["r"]:
                            top_r_loop_size[operand][level + 1] *= loop_dim
                        else:
                            break
                    for loop_type, loop_dim in reversed(current_level_loops):
                        if loop_type in self.layer_node.operand_loop_dim[operand]["ir"]:
                            top_ir_loop_size[operand][level + 1] *= loop_dim
                        else:
                            break

        self.top_r_loop_size = top_r_loop_size
        self.top_ir_loop_size = top_ir_loop_size


And here is the temporal_mapping_generator.py from the stages of the Zigzag

program two: temporal_mapping_generator.py is responsibel for the generation of the temporal maps for a given spatial map which are used by the above script to generate the json file.

import logging
from typing import Any, Generator

from zigzag.hardware.architecture.accelerator import Accelerator
from zigzag.mapping.spatial_mapping_internal import SpatialMappingInternal
from zigzag.mapping.temporal_mapping import TemporalMapping
from zigzag.opt.loma.engine import LomaEngine
from zigzag.opt.loma.memory_allocator import MemoryAllocator
from zigzag.opt.loma.multipermute import PermutationConstraint
from zigzag.stages.stage import Stage, StageCallable
from zigzag.workload.layer_node import LayerNode

logger = logging.getLogger(__name__)


class TemporalMappingGeneratorStage(Stage):
    """! Class that iterates through the different temporal mappings generated through the loop order based memory
    allocation (loma) engine or defined by the user as mapping input.
    """

    def __init__(
        self,
        list_of_callables: list[StageCallable],
        *,
        accelerator: Accelerator,
        layer: LayerNode,
        spatial_mapping: SpatialMappingInternal,
        **kwargs: Any,
    ):
        """
        @param list_of_callables (List[Callable]): List of substages to call with each generated temporal mapping.
        """
        super().__init__(list_of_callables, **kwargs)
        self.accelerator = accelerator
        self.layer = layer
        self.spatial_mapping = spatial_mapping

    def run(self):
        for temporal_mapping in self.generate_temporal_mappings():
            kwargs = self.kwargs.copy()
            kwargs["accelerator"] = self.accelerator
            kwargs["layer"] = self.layer
            kwargs["spatial_mapping"] = self.spatial_mapping
            kwargs["temporal_mapping"] = temporal_mapping
            sub_stage: Stage = self.list_of_callables[0](self.list_of_callables[1:], **kwargs)
            for cme, extra_info in sub_stage.run():
                yield cme, (temporal_mapping, extra_info)

    def generate_temporal_mappings(self) -> Generator[TemporalMapping, None, None]:
        engine = LomaEngine(
            accelerator=self.accelerator,
            layer=self.layer,
            spatial_mapping=self.spatial_mapping,
            **self.kwargs,
        )

        # Return the full, user-provided temporal mapping
        provided_ordering = self.layer.temporal_ordering
        all_temporal_loops = engine.get_temporal_loops()
        if provided_ordering.is_complete(all_temporal_loops):
            allocator = MemoryAllocator(
                self.accelerator, self.layer, self.spatial_mapping, provided_ordering.to_legacy_format()  # type: ignore
            )
            temporal_mapping = allocator.run()
            yield temporal_mapping
            return
        else:
            constraints: list[PermutationConstraint] = provided_ordering.get_constraints()
            if any(not constr.is_empty() for constr in constraints):
                engine.set_constraints(constraints)

            # Generate from scratch
            for mapping in engine.run():
                yield mapping


And finally this is how the zigzag is run and the temporal map is captured using the monkey capture

Program three: main.py - This program runs the zigzag by taking all the inputs of architecture, workload and mapping constraints

import json
import logging
import os
import sys

# ZigZag imports
from zigzag.api import get_hardware_performance_zigzag
from zigzag.stages.mapping.spatial_mapping_generation import SpatialMappingGeneratorStage
from zigzag.stages.mapping.temporal_mapping_generator_stage import TemporalMappingGeneratorStage
from zigzag.visualization.results.plot_cme import bar_plot_cost_model_evaluations_breakdown
from zigzag.visualization.results.print_mapping import print_mapping

# Initialize the logger
logging_level = logging.INFO
logging_format = "%(asctime)s - %(name)s.%(funcName)s +%(lineno)s - %(levelname)s - %(message)s"
logging.basicConfig(level=logging_level, format=logging_format)

sys.path.insert(0, os.getcwd())  # For importing zigzag

# Define output JSON file
output_json = os.path.expanduser("~/Thesis/zigzag/Extras/zigzag_tutorials/zigzag-tutorial/Self_tests/April_experiments/results-06-04/outputs_1/all_mappings.json")
os.makedirs(os.path.dirname(output_json), exist_ok=True)

# Create global dictionaries to store mappings
all_mappings = {}
spatial_count = 0
temporal_count = 0

# Create helper conversion functions
def convert_mapping_to_dict(mapping):
    """Convert any mapping to a dictionary format."""
    try:
        # Handle MappingSingleOADim objects specifically
        if hasattr(mapping, "__class__") and mapping.__class__.__name__ == "MappingSingleOADim":
            if hasattr(mapping, "items"):
                return {str(dim): int(size) for dim, size in mapping.items()}
            elif hasattr(mapping, "__dict__"):
                return {k: convert_mapping_to_dict(v) for k, v in mapping.__dict__.items() 
                        if not k.startswith("_")}
            else:
                return str(mapping)
            
        # Handle normal mapping_dict attribute
        if hasattr(mapping, "mapping_dict"):
            return {str(k): {str(dim): int(size) for dim, size in v.items()} 
                    for k, v in mapping.mapping_dict.items()}
            
        # Handle loop_dim_size attribute
        elif hasattr(mapping, "loop_dim_size"):
            return {str(k): {str(dim): int(size) for dim, size in v.items()} 
                    for k, v in mapping.loop_dim_size.items()}
                    
        # Handle dictionary-like objects
        elif hasattr(mapping, "items"):
            result = {}
            for k, v in mapping.items():
                # Convert both key and value
                key = str(k)
                if hasattr(v, "items") or hasattr(v, "__dict__") or hasattr(v, "mapping_dict"):
                    value = convert_mapping_to_dict(v)
                else:
                    # Try to convert to basic Python types
                    try:
                        value = int(v)
                    except (TypeError, ValueError):
                        try:
                            value = float(v)
                        except (TypeError, ValueError):
                            value = str(v)
                result[key] = value
            return result
            
        # Handle any object with __dict__
        elif hasattr(mapping, "__dict__"):
            return {k: convert_mapping_to_dict(v) for k, v in mapping.__dict__.items() 
                    if not k.startswith("_")}
                    
        # Default to string representation
        return str(mapping)
        
    except Exception as e:
        return f"Error converting mapping: {str(e)}"

# Function to safely save mappings to JSON
def save_mappings_to_json(mappings, filepath):
    # Convert all objects to JSON-serializable dictionaries
    serializable_mappings = {}
    for key, value in mappings.items():
        if isinstance(value, dict):
            # Handle nested dictionaries
            processed_value = {}
            for k, v in value.items():
                if k == "spatial_mapping" or k == "temporal_mappings":
                    if isinstance(v, list):
                        processed_value[k] = [convert_mapping_to_dict(item) for item in v]
                    else:
                        processed_value[k] = convert_mapping_to_dict(v)
                else:
                    processed_value[k] = v
            serializable_mappings[key] = processed_value
        else:
            serializable_mappings[key] = convert_mapping_to_dict(value)
    
    # Save to file
    with open(filepath, 'w') as f:
        json.dump(serializable_mappings, f, indent=2)

# Store original methods
original_spatial_run = SpatialMappingGeneratorStage.run
original_temporal_run = TemporalMappingGeneratorStage.run

# Monkey patch the spatial mapping generator
def patched_spatial_run(self):
    global spatial_count
    layer_id = getattr(self.layer, "id", getattr(self.layer, "name", "unknown"))
    print(f"Running patched spatial mapping generator for layer: {layer_id}")
    
    # Collect all spatial mappings first
    generated_mappings = list(self.generate_spatial_mappings())
    print(f"Generated {len(generated_mappings)} spatial mappings")
    
    # Capture each spatial mapping
    for i, generated_mapping in enumerate(generated_mappings):
        # Extract mapping info before yielding it
        spatial_id = f"spatial_{spatial_count}"
        spatial_count += 1
        
        # Convert to dictionary - will be converted again when saving
        mapping_dict = generated_mapping  # Store original for now
        
        # Save in our global dictionary
        all_mappings[spatial_id] = {
            "layer_id": layer_id,
            "spatial_mapping": mapping_dict,
            "temporal_mappings": []
        }
        
        print(f"Captured spatial mapping {spatial_id}: {generated_mapping}")
        
        # Set on layer as the original method does
        self.layer.spatial_mapping = generated_mapping
        
        # Save periodically
        if len(all_mappings) % 5 == 0:
            try:
                save_mappings_to_json(all_mappings, output_json)
            except Exception as e:
                print(f"Error saving spatial mappings: {e}")
    
    # Run the original method to continue the pipeline
    for result in original_spatial_run(self):
        yield result

# Monkey patch the temporal mapping generator
def patched_temporal_run(self):
    global temporal_count
    layer_id = getattr(self.layer, "id", getattr(self.layer, "name", "unknown"))
    print(f"Running patched temporal mapping generator for layer: {layer_id}")
    
    # Find the corresponding spatial mapping
    current_spatial_id = None
    for spatial_id, mapping_data in all_mappings.items():
        if mapping_data["layer_id"] == layer_id:
            # This is a simple approximation - in reality we'd want to match the exact mapping
            current_spatial_id = spatial_id
            break
    
    print(f"Processing temporal mappings for spatial mapping: {current_spatial_id}")
    
    if current_spatial_id is None:
        print("WARNING: Could not find matching spatial mapping - creating one")
        spatial_id = f"spatial_fallback_{spatial_count}"
        all_mappings[spatial_id] = {
            "layer_id": layer_id,
            "spatial_mapping": self.spatial_mapping,  # Will be converted when saving
            "temporal_mappings": []
        }
        current_spatial_id = spatial_id
    
    # Get all temporal mappings
    temporal_mappings = list(self.generate_temporal_mappings())
    print(f"Generated {len(temporal_mappings)} temporal mappings")
    
    # Save each temporal mapping
    for i, temporal_mapping in enumerate(temporal_mappings):
        # Store original mapping object - will be converted when saving
        all_mappings[current_spatial_id]["temporal_mappings"].append(temporal_mapping)
        temporal_count += 1
        
        # Save periodically
        if temporal_count % 1000 == 0:
            try:
                save_mappings_to_json(all_mappings, output_json)
                print(f"Saved {temporal_count} temporal mappings")
            except Exception as e:
                print(f"Error saving temporal mappings: {e}")
    
    # Run the original method to continue the pipeline
    for result in original_temporal_run(self):
        yield result

# Apply the monkey patches
SpatialMappingGeneratorStage.run = patched_spatial_run
TemporalMappingGeneratorStage.run = patched_temporal_run
print("Monkey patching applied successfully")

# Define the experiment id and pickle name
hw_name = "single_core_8_NPE_event_driven_accelerator"
workload_name = "lenet_5_first_layer"
experiment_id = f"{hw_name}-{workload_name}"
pickle_name = f"{experiment_id}-saved_list_of_cmes"

# Define main input paths
accelerator_path = os.path.expanduser("~/Thesis/zigzag/Extras/zigzag_tutorials/zigzag-tutorial/Self_tests/April_experiments/results-06-04/inputs/architecture/single_core_8_NPE_event_driven_accelerator.yaml")
workload_path = os.path.expanduser("~/Thesis/zigzag/Extras/zigzag_tutorials/zigzag-tutorial/Self_tests/April_experiments/results-06-04/inputs/workload/lenet_5_first_layer.yaml")
mapping_path = os.path.expanduser("~/Thesis/zigzag/Extras/zigzag_tutorials/zigzag-tutorial/Self_tests/April_experiments/results-06-04/inputs/mapping/lenet_first_layer.yaml")

# Define other inputs of api call
temporal_mapping_search_engine = "lowa"
optimization_criterion = "latency"
dump_folder = os.path.expanduser(f"~/Thesis/zigzag/Extras/zigzag_tutorials/zigzag-tutorial/Self_tests/April_experiments/results-06-04/outputs/{experiment_id}")
pickle_filename = os.path.expanduser(f"~/Thesis/zigzag/Extras/zigzag_tutorials/zigzag-tutorial/Self_tests/April_experiments/results-06-04/outputs/{pickle_name}.pickle")

print("Starting ZigZag run...")
# Get the hardware performance through api call
result = get_hardware_performance_zigzag(
    accelerator=accelerator_path,
    workload=workload_path,
    mapping=mapping_path,
    temporal_mapping_search_engine=temporal_mapping_search_engine,
    opt=optimization_criterion,
    dump_folder=dump_folder,
    pickle_filename=pickle_filename,
    nb_spatial_mappings_generated=3,  # Increase for more spatial mappings
    # lpf_limit=100,  # Increase for more temporal mappings
)
print("ZigZag run completed")

if len(result) == 3:
    energy, latency, results = result
elif len(result) == 5:
    energy, latency, _, _, results = result
else:
    raise ValueError("Unexpected result length from get_hardware_performance_zigzag")

# Extract the CMEs from the results
cmes = [result[0] for result in results[0][1]]

# Save a bar plot of the cost model evaluations breakdown
save_path = os.path.expanduser("~/Thesis/zigzag/Extras/zigzag_tutorials/zigzag-tutorial/Self_tests/April_experiments/results-06-04/outputs/breakdown.png")
bar_plot_cost_model_evaluations_breakdown(cmes, save_path=save_path)
print_mapping(cmes[0])

# Save final mappings
try:
    save_mappings_to_json(all_mappings, output_json)
    print(f"Final mapping count: {len(all_mappings)} spatial mappings")
    print(f"Total temporal mappings: {sum(len(m.get('temporal_mappings', [])) for m in all_mappings.values())}")
    print(f"All mappings saved to: {output_json}")
except Exception as e:
    print(f"Error saving final mappings: {e}")


With the provided context, Can you in detail variable by variable explain the json output I shared. I need this explanation to understand on how to get/extract input stationary mappings from all the mappings generated by the zigzag?



#### Answer 1: 
The final table of the explanation is stored in the miro and here is the final answer from the grok

### Key Points
- Research suggests that input stationary mappings can be identified by analyzing the loop order in the "mapping_dic_stationary" for operand 'I', focusing on consecutive irrelevant loops at the innermost level.
- It seems likely that mappings with a higher product of loop dimensions for these innermost irrelevant loops for 'I' are more input stationary, indicating better input data reuse.
- The evidence leans toward using the "mac_level_data_stationary_cycle" for 'I' as an additional indicator, though it may not always align with the innermost loop analysis.

---

### Direct Answer

#### Understanding the JSON Output
The JSON output from your `all_mapping.json` file contains detailed information about temporal mappings generated by ZigZag for a given workload and architecture. Each variable in the JSON provides insights into how the computation is mapped, which helps identify input stationary mappings where the input data ('I') is kept stationary for reuse. Below, I’ll explain each variable to help you extract these mappings.

##### What Each Variable Means
- **temporal_mappings**: This is the main object containing all temporal mapping information for the layer.
  - **mapping_dic_origin**: Shows the original temporal mapping dictionary for operands ('O', 'W', 'I'), with loop orders like [(K, 6), (IY, 8), ...]. It represents the initial loop structure before processing.
  - **layer_node**: Details about the layer, including its ID, name ("layer_1"), type ("Conv"), and dimensions (e.g., B=1, K=6, IY=32). It’s crucial for understanding which loops are relevant or irrelevant for each operand.
  - **operand_list**: Lists the operands involved ([O, W, I]), which are output, weights, and input, respectively.
  - **mem_level**: Indicates the memory hierarchy level for each operand (all 1 here, meaning one level), affecting how data is stored and accessed.
  - **mapping_dic_stationary**: The processed temporal mapping after merging irrelevant loops, showing the final loop order for each operand, e.g., [[(K, 6), (IY, 8), ...]] for 'I'.
  - **mac_level_data_stationary_cycle**: Shows how many cycles each operand is stationary at the MAC level (e.g., 'I' is 6, meaning input is stationary for 6 cycles, possibly indicating reuse).
  - **cycle_cabl_level**: Lists cycles covered at each memory level (e.g., [30720] for 'I'), reflecting total computation cycles.
  - **total_cycle**: The overall cycle count (30720 here), important for performance analysis.
  - **top_r_loop_size** and **top_ir_loop_size**: Indicate the product of innermost relevant (r) and irrelevant (ir) loops at each level, e.g., for 'I', top_ir_loop_size [1, 5] suggests 5 cycles of irrelevant loops innermost, good for input stationarity.
  - Other fields like operand_size_elem, operand_data_reuse, etc., provide layer-specific data but are less relevant for mapping analysis.

##### Extracting Input Stationary Mappings
To find input stationary mappings, focus on ensuring the input ('I') is reused by keeping its irrelevant loops (e.g., FX, FY, K) innermost in the loop order. Here’s how:
1. Look at **mapping_dic_stationary** for 'I' (e.g., [(K, 6), (IY, 8), (IY, 4), (IX, 8), (IX, 4), (FY, 5)]). From the end, count consecutive loops that are irrelevant for 'I' (from layer_node.ir_dims, e.g., FX, FY, K). Here, only FY=5 is irrelevant at the end, product=5.
2. Use **top_ir_loop_size** for 'I' (e.g., [1, 5]) to see the product of innermost irrelevant loops, which should be high for input stationarity.
3. Check **mac_level_data_stationary_cycle** for 'I' (e.g., 6), which may indicate stationarity but is based on outermost irrelevant loops, so prioritize the innermost analysis.
4. Filter mappings where the product of consecutive innermost irrelevant loops for 'I' is high, suggesting better input reuse, making them input stationary.

By analyzing these, you can extract mappings where input data is kept stationary, enhancing reuse and potentially matching your event-driven map needs.

---

### Survey Note: Comprehensive Analysis of ZigZag Mapping JSON Output for Input Stationary Extraction

This section provides a detailed exploration of the JSON output from the `all_mapping.json` file generated by ZigZag, focusing on understanding each variable to extract input stationary mappings for a given deep learning workload and architecture. The analysis is grounded in the provided code snippets (`temporal_mapping.py`, `temporal_mapping_generator.py`, and `main.py`) and the user's specific needs, ensuring a thorough understanding for researchers and practitioners in hardware mapping design space exploration.

#### Background and Context
ZigZag is a hardware architecture-mapping design space exploration (DSE) framework for deep learning (DL) accelerators, bridging the gap between algorithmic DL decisions and their hardware acceleration cost through fast and accurate analytical cost estimation. A critical component is the generation of temporal and spatial mappings, which are evaluated to optimize metrics like energy, latency, or Energy-Delay Product (EDP). The user seeks to understand the JSON output to extract input stationary mappings, where the input data ('I') is kept stationary for reuse, potentially aligning with their need for event-driven maps. The JSON output is generated by scripts that collect and process temporal mappings, as detailed in the provided programs.

The process involves multiple stages, with `temporal_mapping_generator.py` generating temporal mappings for a given spatial mapping, `temporal_mapping.py` collecting and processing this information into JSON, and `main.py` orchestrating the overall ZigZag execution. The JSON snippet provided contains detailed mapping information, and the goal is to decipher each variable to identify input stationary mappings.

#### Detailed Variable-by-Variable Explanation
The JSON output is structured under "temporal_mappings", with various fields providing insights into the temporal mapping and layer details. Below is a comprehensive explanation of each variable, supported by the code and context:

| **Variable**                     | **Description**                                                                                     | **Relevance to Input Stationary Mapping**                                                                 |
|-----------------------------------|-----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|
| **mapping_dic_origin**            | Original temporal mapping dictionary for operands ('O', 'W', 'I'), with loop orders like [[(K, 6), (IY, 8), ...]]. Represents initial loop structure before processing. | Shows initial loop order; for 'I', irrelevant loops (e.g., K, FY) at the end suggest potential input stationarity. |
| **layer_node**                    | Detailed layer information, including ID ("0"), name ("layer_1"), type ("Conv"), equation, dimensions (e.g., B=1, K=6, IY=32), and operand precision. | Provides context for loop relevancy; "loop_relevancy_info" identifies relevant (r) and irrelevant (ir) loops for 'I' (r=[IY, IX], ir=[FX, FY, K]), crucial for stationarity analysis. |
| **operand_list**                  | List of operands involved ([O, W, I]), representing output, weights, and input, respectively.        | Defines which operands to analyze; focus on 'I' for input stationarity.                                   |
| **mem_level**                     | Memory hierarchy level for each operand (e.g., all 1, meaning one level). Affects data storage and access. | With one level, all loops are at the same memory level; impacts how stationarity is computed at MAC level. |
| **mapping_dic_stationary**        | Processed temporal mapping after merging irrelevant loops, showing final loop order for each operand, e.g., [[(K, 6), (IY, 8), (IY, 4), (IX, 8), (IX, 4), (FY, 5)]] for 'I'. | Key for analysis; for 'I', loop order from outermost (K) to innermost (FY) determines stationarity; ir loops at the end (e.g., FY) indicate input reuse. |
| **mac_level_data_stationary_cycle** | Number of cycles each operand is stationary at the MAC level (e.g., 'I': 6, 'W': 1, 'O': 1). Computed as product of outermost irrelevant loops at level 0. | For 'I', 6 (size of K) suggests stationarity during K iterations, but may not reflect innermost reuse; useful as secondary indicator. |
| **cycle_cabl_level**              | Cycles covered at each memory level (e.g., [30720] for 'I'), computed as product of loop dimensions from level 0 to current level. | Reflects total computation cycles; higher values may indicate more opportunities for data reuse, but not specific to stationarity. |
| **total_cycle**                   | Overall cycle count (30720 here), derived from cycle_cabl_level at the highest level.                | Performance metric; not directly relevant for stationarity, but context for mapping efficiency.            |
| **top_r_loop_size**               | Product of innermost relevant (r) loops at each level (e.g., 'I': [1, 1], 'W': [1, 5]). Computed from innermost to outermost, stopping at first ir loop. | For 'I', [1, 1] means no significant r loops innermost; low values suggest potential for input stationarity if ir loops dominate. |
| **top_ir_loop_size**              | Product of innermost irrelevant (ir) loops at each level (e.g., 'I': [1, 5], 'W': [1, 1]). Computed similarly. | For 'I', [1, 5] (FY=5 innermost) indicates 5 cycles of ir loops, key for input stationarity; higher values suggest better input reuse. |
| **operand_size_elem**             | Size of each operand in elements (e.g., 'I': 1024, 'W': 150, 'O': 7776), based on layer dimensions. | Layer-specific; used to compute data reuse, but not mapping-dependent; context for understanding scale.    |
| **total_mac_count**               | Total multiply-accumulate operations (153600 here), derived from layer computation.                  | Performance metric; used to compute operand_data_reuse, but not directly for stationarity analysis.        |
| **operand_size_bit**              | Size of each operand in bits (e.g., 'I': 16384, computed as operand_size_elem * precision).          | Layer-specific; provides context for memory requirements, but not for mapping analysis.                   |
| **operand_data_reuse**            | Average number of times each operand element is used (e.g., 'I': 150, computed as total_mac_count / operand_size_elem). | High for 'I' (150) indicates layer-level reuse; useful context, but not mapping-specific for stationarity. |

#### Extracting Input Stationary Mappings
To extract input stationary mappings, the goal is to identify mappings where the input operand 'I' is kept stationary, maximizing reuse by ensuring its irrelevant loops (e.g., FX, FY, K) are placed innermost in the loop order. The analysis involves the following steps, derived from the JSON fields and code logic:

1. **Analyze Loop Order in mapping_dic_stationary for 'I'**:
   - Parse the loop list for 'I', e.g., [(K, 6), (IY, 8), (IY, 4), (IX, 8), (IX, 4), (FY, 5)]. The order is from outermost (K) to innermost (FY).
   - Identify irrelevant loops for 'I' from layer_node.loop_relevancy_info.ir_dims, e.g., [FX, FY, K]. In the example, K and FY are ir, while IY and IX are relevant.
   - Starting from the end (innermost), count consecutive loops that are ir. In the example, FY=5 is ir, then IX is relevant, so only FY is consecutive, product=5.
   - This product represents the number of cycles the input is stationary at the MAC level, as it indicates how many iterations the input remains fixed while ir loops iterate.

2. **Leverage top_ir_loop_size for 'I'**:
   - Check top_ir_loop_size for 'I' (e.g., [1, 5]), where the second element (5) is the product of innermost ir loops at memory level 0. This aligns with the product computed above (FY=5), confirming 5 cycles of stationarity.
   - Mappings with higher top_ir_loop_size for 'I' suggest better input stationarity, as more ir loops innermost mean more reuse opportunities.

3. **Consider mac_level_data_stationary_cycle for 'I'**:
   - For 'I', it's 6 (size of K), computed as the product of outermost ir loops at level 0. This indicates stationarity during K iterations, but since K is outermost, it may not reflect innermost reuse.
   - Use as a secondary indicator; prioritize mappings where both mac_level_data_stationary_cycle and innermost ir loop product are high, though they may not always align.

4. **Filter and Sort Mappings**:
   - Across all mappings in `all_mapping.json`, compute the product of consecutive innermost ir loops for 'I' for each mapping.
   - Sort or filter mappings with the highest products, as these are likely more input stationary, enhancing input data reuse and potentially aligning with event-driven map needs.

#### Considerations and Limitations
- **Loop Order Interpretation**: The loop order in mapping_dic_stationary is from outermost to innermost, and the analysis assumes consecutive ir loops at the end indicate stationarity. This may vary with different layer dimensions or mappings, requiring validation.
- **Threshold for Stationarity**: The user may need to set a threshold for the product of ir loops, but without specific values, selecting the top percentile (e.g., top 10%) could work, depending on the total number of mappings.
- **Event-Driven Map Alignment**: The user's mention of "event drive map" suggests input stationarity may be part, but exact alignment needs further context. The approach here assumes high input reuse aligns with this need.
- **Performance Impact**: Analyzing all mappings (potentially 1 million, as mentioned) may be computationally intensive, so consider batch processing or sampling for large datasets.

#### Conclusion
Understanding the JSON output from ZigZag's mapping exploration involves deciphering each variable to extract input stationary mappings. By focusing on mapping_dic_stationary for 'I', computing the product of consecutive innermost irrelevant loops, and leveraging top_ir_loop_size, you can identify mappings with high input stationarity. This method ensures you capture mappings where input data is reused effectively, potentially meeting your event-driven map requirements, while considering secondary indicators like mac_level_data_stationary_cycle for robustness.

---

### Key Citations
- [ZigZag GitHub Repository Mapping](https://github.com/KULeuven-MICAS/zigzag)
- [Input Stationary Dataflow in Deep Learning Accelerators](https://arxiv.org/html/2403.09026v1)
- [INCA Input-stationary Dataflow Deep Learning Accelerators](https://ieeexplore.ieee.org/document/10070992)

